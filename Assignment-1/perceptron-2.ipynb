{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[159, -177.49748999999036, -92.41150799999488, -127.59865000000123, -12.079659000000207]\n",
      "Classifiaction Accuary\n",
      "98.90590809628009\n"
     ]
    }
   ],
   "source": [
    "#Non -Normalized\n",
    "csvData  = pd.read_csv(\"Dataset Question2.csv\")\n",
    "trainData = np.array(csvData)\n",
    "\n",
    "if len(trainData) != 0 :\n",
    "    trainDataLength = len(trainData)\n",
    "else :\n",
    "    exit()\n",
    "    \n",
    "bias = 1\n",
    "numOfParameters = len(trainData[0]) \n",
    "weightVector =random.sample(range(1,11),numOfParameters ) \n",
    "trainVector = trainData[:trainDataLength , 0:(numOfParameters-1)] \n",
    "lossVector = []\n",
    "errVector = []\n",
    "accVector = []\n",
    "count = 0\n",
    "#Perceptron Algorithm \n",
    "#print(weightVector)\n",
    "for i in range(1,201) :\n",
    "    count = 0\n",
    "    for j in range(trainDataLength) :\n",
    "        \n",
    "        x = [bias] + list(trainVector[j])\n",
    "        res= [i1*j1 for (i1,j1) in zip(x,weightVector)] #vector sum\n",
    "        \n",
    "        if (sum(res) < 0 and trainData[j][numOfParameters-1] == 1) :\n",
    "            weightVector = [i1+j1 for (i1,j1) in zip(weightVector,x)]\n",
    "            count = count + 1\n",
    "    \n",
    "        elif (sum(res) >= 0 and trainData[j][numOfParameters-1] == 0): \n",
    "            weightVector = [i1-j1 for (i1,j1) in zip(weightVector,x)]\n",
    "            count = count + 1\n",
    "    lossVector.append(count)\n",
    "    errVector.append((count/trainDataLength)*100)\n",
    "    accVector.append(((trainDataLength-count)/trainDataLength)*100)\n",
    "    \n",
    "                   \n",
    "print(weightVector)\n",
    "print(\"Classifiaction Accuary\")\n",
    "print((trainDataLength-count)/(trainDataLength)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21.63703267333283, -14.147521731475837, -3.801095225895744, -11.022718665473894, 12.538597619005643]\n",
      "Classifiaction Accuracy\n",
      "96.93654266958424\n"
     ]
    }
   ],
   "source": [
    "#Non -Normalized\n",
    "csvData  = pd.read_csv(\"Dataset Question2.csv\")\n",
    "trainData = np.array(csvData)\n",
    "\n",
    "if len(trainData) != 0 :\n",
    "    trainDataLength = len(trainData)\n",
    "else :\n",
    "    exit()\n",
    "    \n",
    "bias = 1\n",
    "numOfParameters = len(trainData[0]) \n",
    "weightVector =random.sample(range(1,7),numOfParameters ) \n",
    "trainVector = trainData[:trainDataLength , 0:(numOfParameters-1)] \n",
    "lossVector = []\n",
    "errVector = []\n",
    "accVector = []\n",
    "count = 0\n",
    "#Perceptron Algorithm \n",
    "#print(weightVector)\n",
    "for i in range(1,101) :\n",
    "    count = 0\n",
    "    for j in range(trainDataLength) :\n",
    "        \n",
    "        x = [bias] + list(trainVector[j])\n",
    "        \n",
    "        x = np.array(x)\n",
    "        #print(x)\n",
    "        x = scaler.fit_transform(x.reshape((len(x),1)))\n",
    "        x = list(x)\n",
    "        x= [float(i1) for i1 in x] \n",
    "        \n",
    "        res= [i1*j1 for (i1,j1) in zip(x,weightVector)] #vector sum\n",
    "        \n",
    "        if (sum(res) < 0 and trainData[j][numOfParameters-1] == 1) :\n",
    "            weightVector = [i1+j1 for (i1,j1) in zip(weightVector,x)]\n",
    "            count = count + 1\n",
    "    \n",
    "        elif (sum(res) >= 0 and trainData[j][numOfParameters-1] == 0): \n",
    "            weightVector = [i1-j1 for (i1,j1) in zip(weightVector,x)]\n",
    "            count = count + 1\n",
    "    lossVector.append(count)\n",
    "    errVector.append((count/trainDataLength)*100)\n",
    "    accVector.append(((trainDataLength-count)/trainDataLength)*100)\n",
    "    \n",
    "                   \n",
    "print(weightVector)\n",
    "print(\"Classifiaction Accuracy\")\n",
    "print((trainDataLength-count)/(trainDataLength)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non - Normalized \n",
    "Accuracy - 98.614%\n",
    "w = [159, -177.49748999999036, -92.41150799999488, -127.59865000000123, -12.079659000000207]\n",
    "# Normalized \n",
    "Accuracy - 96.93% \n",
    "w = [21.63703267333283, -14.147521731475837, -3.801095225895744, -11.022718665473894, 12.538597619005643]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
