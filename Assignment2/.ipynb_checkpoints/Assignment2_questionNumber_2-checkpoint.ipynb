{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import LeakyReLU\n",
    "mnist = tf.keras.datasets.mnist \n",
    "\n",
    "(x_train , y_train) , (x_test , y_test) = mnist.load_data() \n",
    "\n",
    "x_validate = [] \n",
    "y_validate = [] \n",
    "\n",
    "x_validate = x_train[55000 : 60000 ]\n",
    "y_validate = y_train[55000 : 60000 ]\n",
    "\n",
    "x_train = x_train[0 : 55000 ]\n",
    "y_train = y_train[0 :  55000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 4s 67us/sample - loss: 1.3805 - acc: 0.5468\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 4s 65us/sample - loss: 0.9645 - acc: 0.6828\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 3s 61us/sample - loss: 0.9141 - acc: 0.6909\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 3s 60us/sample - loss: 1.0216 - acc: 0.6414\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 3s 61us/sample - loss: 1.0000 - acc: 0.6531\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 4s 65us/sample - loss: 0.9461 - acc: 0.6761\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 3s 62us/sample - loss: 0.8515 - acc: 0.7179\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 3s 59us/sample - loss: 0.8062 - acc: 0.7226\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 3s 56us/sample - loss: 0.8119 - acc: 0.7372\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 3s 56us/sample - loss: 0.8084 - acc: 0.7342\n",
      "Performance with validationData :\n",
      "5000/5000 [==============================] - 0s 54us/sample - loss: 0.6613 - acc: 0.7822\n",
      "Performance with testData :\n",
      "10000/10000 [==============================] - 0s 33us/sample - loss: 0.7418 - acc: 0.7532\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(32 , activation = tf.nn.sigmoid))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(10 , activation = tf.nn.softmax))\n",
    "\n",
    "sgd = tf.compat.v1.keras.optimizers.SGD(learning_rate = 0.1 )\n",
    "\n",
    "model.compile( optimizer = sgd , \n",
    "             loss = 'sparse_categorical_crossentropy' ,\n",
    "             metrics = ['accuracy'] ) \n",
    "\n",
    "model.fit(x_train , y_train , epochs = 10 )\n",
    "\n",
    "print(\"Performance with validationData :\")\n",
    "val_loss , val_acc = model.evaluate(x_validate,y_validate)\n",
    "print(\"Performance with testData :\")\n",
    "val_loss , val_acc = model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without normalizing data \n",
    "\n",
    "epochs set as 10 \n",
    "\n",
    "number of hidden layer is 1 and it has 32 nodes .activation used is sigmoid\n",
    "\n",
    "output has 10 layers and activation used is softmax \n",
    "\n",
    "Performance :\n",
    "\n",
    "Performance with validationData :\n",
    "acc: 0.7822\n",
    "\n",
    "Performance with testData :\n",
    "acc: 0.7532\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 3s 61us/sample - loss: 0.9899 - acc: 0.7706\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 3s 59us/sample - loss: 0.4107 - acc: 0.8877\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 3s 60us/sample - loss: 0.3420 - acc: 0.9031\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 3s 59us/sample - loss: 0.3090 - acc: 0.9123\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 3s 60us/sample - loss: 0.2865 - acc: 0.9179\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 3s 63us/sample - loss: 0.2688 - acc: 0.9233\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 3s 58us/sample - loss: 0.2541 - acc: 0.9275\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 3s 57us/sample - loss: 0.2417 - acc: 0.9309\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 3s 58us/sample - loss: 0.2306 - acc: 0.9342\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 3s 58us/sample - loss: 0.2210 - acc: 0.9368\n",
      "Performance with validationData :\n",
      "5000/5000 [==============================] - 0s 50us/sample - loss: 0.1840 - acc: 0.9484\n",
      "Performance with testData :\n",
      "10000/10000 [==============================] - 0s 35us/sample - loss: 0.2172 - acc: 0.9365\n"
     ]
    }
   ],
   "source": [
    "x_train = tf.keras.utils.normalize(x_train , axis = 1 )\n",
    "x_test = tf.keras.utils.normalize(x_test , axis = 1 )\n",
    "x_validate = tf.keras.utils.normalize(x_validate , axis = 1 ) \n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(tf.keras.layers.Dense(32 , activation = tf.nn.sigmoid))\n",
    "model.add(tf.keras.layers.Dense(10 , activation = tf.nn.softmax))\n",
    "\n",
    "sgd = tf.compat.v1.keras.optimizers.SGD(learning_rate = 0.1 )\n",
    "\n",
    "model.compile( optimizer = sgd , \n",
    "             loss = 'sparse_categorical_crossentropy' ,\n",
    "             metrics = ['accuracy'] ) \n",
    "\n",
    "model.fit(x_train , y_train , epochs = 10  )\n",
    "\n",
    "print(\"Performance with validationData :\")\n",
    "val_loss , val_acc = model.evaluate(x_validate,y_validate)\n",
    "print(\"Performance with testData :\")\n",
    "val_loss , val_acc = model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With normalizing data \n",
    "\n",
    "epochs set as 10 \n",
    "\n",
    "number of hidden layer is 1 and it has 32 nodes .activation used is sigmoid\n",
    "\n",
    "output has 10 layers and activation used is softmax \n",
    "\n",
    "Performance :\n",
    "\n",
    "Performance with validationData :\n",
    "    \n",
    "acc:  0.9484\n",
    "    \n",
    "Performance with testData :\n",
    "    \n",
    "acc: 0.9365"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation : Normalised data is performing well "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 4s 64us/sample - loss: 1.6423 - acc: 0.4900\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 3s 62us/sample - loss: 0.6281 - acc: 0.8250\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 3s 62us/sample - loss: 0.4404 - acc: 0.8788\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 3s 60us/sample - loss: 0.3665 - acc: 0.8965\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 3s 61us/sample - loss: 0.3207 - acc: 0.9082\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 3s 59us/sample - loss: 0.2885 - acc: 0.9176\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 3s 61us/sample - loss: 0.2636 - acc: 0.9243\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 3s 63us/sample - loss: 0.2428 - acc: 0.9306\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 3s 63us/sample - loss: 0.2257 - acc: 0.9349\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 4s 65us/sample - loss: 0.2106 - acc: 0.9401\n",
      "Performance with validationData :\n",
      "5000/5000 [==============================] - 0s 54us/sample - loss: 0.1752 - acc: 0.9510\n",
      "Performance with testData :\n",
      "10000/10000 [==============================] - 0s 41us/sample - loss: 0.2099 - acc: 0.9386\n"
     ]
    }
   ],
   "source": [
    "x_train = tf.keras.utils.normalize(x_train , axis = 1 )\n",
    "x_test = tf.keras.utils.normalize(x_test , axis = 1 )\n",
    "x_validate = tf.keras.utils.normalize(x_validate , axis = 1 ) \n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(tf.keras.layers.Dense(32 , activation = tf.nn.sigmoid))\n",
    "model.add(tf.keras.layers.Dense(32 , activation = tf.nn.sigmoid))\n",
    "model.add(tf.keras.layers.Dense(10 , activation = tf.nn.softmax))\n",
    "\n",
    "sgd = tf.compat.v1.keras.optimizers.SGD(learning_rate = 0.1 )\n",
    "\n",
    "model.compile( optimizer = sgd , \n",
    "             loss = 'sparse_categorical_crossentropy' ,\n",
    "             metrics = ['accuracy'] ) \n",
    "\n",
    "model.fit(x_train , y_train , epochs = 10  )\n",
    "\n",
    "print(\"Performance with validationData :\")\n",
    "val_loss , val_acc = model.evaluate(x_validate,y_validate)\n",
    "print(\"Performance with testData :\")\n",
    "val_loss , val_acc = model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With normalizing data \n",
    "\n",
    "epochs set as 10 \n",
    "\n",
    "number of hidden layer used are 2 and it has 32 nodes .activation used is sigmoid\n",
    "\n",
    "output has 10 layers and activation used in output layer is softmax \n",
    "\n",
    "Performance :\n",
    "\n",
    "Performance with validationData :\n",
    "    \n",
    "acc: 0.9510\n",
    "    \n",
    "Performance with testData :\n",
    "    \n",
    "acc: 0.9386"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 4s 65us/sample - loss: 2.2908 - acc: 0.1299\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 4s 65us/sample - loss: 1.5994 - acc: 0.4657\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 4s 65us/sample - loss: 0.8048 - acc: 0.7643\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 4s 65us/sample - loss: 0.5740 - acc: 0.8381\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 4s 64us/sample - loss: 0.4741 - acc: 0.8672\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 3s 63us/sample - loss: 0.4129 - acc: 0.8834\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 3s 63us/sample - loss: 0.3626 - acc: 0.8976\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 3s 62us/sample - loss: 0.3187 - acc: 0.9103\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 3s 61us/sample - loss: 0.2817 - acc: 0.9201\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 3s 62us/sample - loss: 0.2516 - acc: 0.9280\n",
      "Performance with validationData :\n",
      "5000/5000 [==============================] - 0s 57us/sample - loss: 0.2013 - acc: 0.9436\n",
      "Performance with testData :\n",
      "10000/10000 [==============================] - 0s 40us/sample - loss: 0.2432 - acc: 0.9298\n"
     ]
    }
   ],
   "source": [
    "x_train = tf.keras.utils.normalize(x_train , axis = 1 )\n",
    "x_test = tf.keras.utils.normalize(x_test , axis = 1 )\n",
    "x_validate = tf.keras.utils.normalize(x_validate , axis = 1 ) \n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(tf.keras.layers.Dense(32 , activation = tf.nn.sigmoid))\n",
    "model.add(tf.keras.layers.Dense(32 , activation = tf.nn.sigmoid))\n",
    "model.add(tf.keras.layers.Dense(32 , activation = tf.nn.sigmoid))\n",
    "model.add(tf.keras.layers.Dense(10 , activation = tf.nn.softmax))\n",
    "\n",
    "sgd = tf.compat.v1.keras.optimizers.SGD(learning_rate = 0.1 )\n",
    "\n",
    "model.compile( optimizer = sgd , \n",
    "             loss = 'sparse_categorical_crossentropy' ,\n",
    "             metrics = ['accuracy'] ) \n",
    "\n",
    "model.fit(x_train , y_train , epochs = 10  )\n",
    "\n",
    "print(\"Performance with validationData :\")\n",
    "val_loss , val_acc = model.evaluate(x_validate,y_validate)\n",
    "print(\"Performance with testData :\")\n",
    "val_loss , val_acc = model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With normalizing data \n",
    "\n",
    "epochs set as 10 \n",
    "\n",
    "number of hidden layer used are 3 and it has 32 nodes .activation used is sigmoid\n",
    "\n",
    "output has 10 layers and activation used in output layer is softmax \n",
    "\n",
    "\n",
    "Performance :\n",
    "\n",
    "Performance with validationData :\n",
    "    \n",
    "acc: 0.9436\n",
    "    \n",
    "Performance with testData :\n",
    "    \n",
    "acc: 0.9298"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obserativation : With number of hidden layer as 2,the model is performing well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 2s 43us/sample - loss: 1.5687 - acc: 0.5073\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 2s 40us/sample - loss: 0.5158 - acc: 0.8569\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 2s 42us/sample - loss: 0.3821 - acc: 0.8908\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 4s 66us/sample - loss: 0.3351 - acc: 0.9034\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 4s 71us/sample - loss: 0.3060 - acc: 0.9122\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 4s 69us/sample - loss: 0.2828 - acc: 0.9183\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 4s 70us/sample - loss: 0.2635 - acc: 0.9243\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 4s 70us/sample - loss: 0.2465 - acc: 0.9283\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 4s 69us/sample - loss: 0.2317 - acc: 0.9330\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 4s 70us/sample - loss: 0.2178 - acc: 0.9373\n",
      "Performance with validationData :\n",
      "5000/5000 [==============================] - 0s 64us/sample - loss: 0.1783 - acc: 0.9522\n",
      "Performance with testData :\n",
      "10000/10000 [==============================] - 0s 43us/sample - loss: 0.2127 - acc: 0.9362\n"
     ]
    }
   ],
   "source": [
    "x_train = tf.keras.utils.normalize(x_train , axis = 1 )\n",
    "x_test = tf.keras.utils.normalize(x_test , axis = 1 )\n",
    "x_validate = tf.keras.utils.normalize(x_validate , axis = 1 ) \n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(tf.keras.layers.Dense(64 , activation = tf.nn.sigmoid))\n",
    "model.add(tf.keras.layers.Dense(64 , activation = tf.nn.sigmoid))\n",
    "model.add(tf.keras.layers.Dense(10 , activation = tf.nn.softmax))\n",
    "\n",
    "sgd = tf.compat.v1.keras.optimizers.SGD(learning_rate = 0.1 )\n",
    "\n",
    "model.compile( optimizer = sgd , \n",
    "             loss = 'sparse_categorical_crossentropy' ,\n",
    "             metrics = ['accuracy'] ) \n",
    "\n",
    "model.fit(x_train , y_train , epochs = 10  )\n",
    "\n",
    "print(\"Performance with validationData :\")\n",
    "val_loss , val_acc = model.evaluate(x_validate,y_validate)\n",
    "print(\"Performance with testData :\")\n",
    "val_loss , val_acc = model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "With normalizing data \n",
    "\n",
    "epochs set as 10 \n",
    "\n",
    "number of hidden layer used are 2 and it has 64 nodes .activation used is sigmoid\n",
    "\n",
    "output has 10 layers and activation used in output layer is softmax \n",
    "\n",
    "Performance :\n",
    "\n",
    "Performance with validationData :\n",
    "    \n",
    "acc: 0.9522\n",
    "    \n",
    "Performance with testData :\n",
    "\n",
    "acc: 0.9362\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 5s 82us/sample - loss: 1.4443 - acc: 0.5349\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 5s 82us/sample - loss: 0.4967 - acc: 0.8559\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 4s 79us/sample - loss: 0.3796 - acc: 0.8903\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 4s 79us/sample - loss: 0.3351 - acc: 0.9032\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 4s 81us/sample - loss: 0.3100 - acc: 0.9104\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 4s 80us/sample - loss: 0.2916 - acc: 0.9152\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 4s 80us/sample - loss: 0.2749 - acc: 0.9210\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 4s 81us/sample - loss: 0.2611 - acc: 0.9234\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 4s 80us/sample - loss: 0.2475 - acc: 0.9278\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 4s 81us/sample - loss: 0.2347 - acc: 0.9314\n",
      "Performance with validationData :\n",
      "5000/5000 [==============================] - 0s 69us/sample - loss: 0.1859 - acc: 0.9466\n",
      "Performance with testData :\n",
      "10000/10000 [==============================] - 0s 48us/sample - loss: 0.2244 - acc: 0.9326\n"
     ]
    }
   ],
   "source": [
    "x_train = tf.keras.utils.normalize(x_train , axis = 1 )\n",
    "x_test = tf.keras.utils.normalize(x_test , axis = 1 )\n",
    "x_validate = tf.keras.utils.normalize(x_validate , axis = 1 ) \n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(tf.keras.layers.Dense(128 , activation = tf.nn.sigmoid))\n",
    "model.add(tf.keras.layers.Dense(128 , activation = tf.nn.sigmoid))\n",
    "model.add(tf.keras.layers.Dense(10 , activation = tf.nn.softmax))\n",
    "\n",
    "sgd = tf.compat.v1.keras.optimizers.SGD(learning_rate = 0.1 )\n",
    "\n",
    "model.compile( optimizer = sgd , \n",
    "             loss = 'sparse_categorical_crossentropy' ,\n",
    "             metrics = ['accuracy'] ) \n",
    "\n",
    "model.fit(x_train , y_train , epochs = 10  )\n",
    "\n",
    "print(\"Performance with validationData :\")\n",
    "val_loss , val_acc = model.evaluate(x_validate,y_validate)\n",
    "print(\"Performance with testData :\")\n",
    "val_loss , val_acc = model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "With normalizing data \n",
    "\n",
    "epochs set as 10 \n",
    "\n",
    "number of hidden layer used are 2 and it has 128 nodes .activation used is sigmoid\n",
    "\n",
    "output has 10 layers and activation used in output layer is softmax \n",
    "\n",
    "Performance :\n",
    "\n",
    "Performance with validationData :\n",
    "    \n",
    "acc: 0.9466\n",
    "    \n",
    "Performance with testData :\n",
    "\n",
    "acc: 0.9326"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation : With number of nodes in hidden layer as 64,the model is performing well\n",
    "    \n",
    "therefore , the good performing model has \n",
    "\n",
    "2 hidden layers ,\n",
    "64 nodes each  ,  \n",
    "should be test with normalized data .\n",
    "hidden layer activation is sigmoid \n",
    "output layer activation is softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 2s 41us/sample - loss: 0.4027 - acc: 0.8828\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 2s 41us/sample - loss: 0.1802 - acc: 0.9460\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 2s 38us/sample - loss: 0.1324 - acc: 0.9601\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 2s 38us/sample - loss: 0.1077 - acc: 0.9670\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 2s 40us/sample - loss: 0.0888 - acc: 0.9725\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 2s 40us/sample - loss: 0.0757 - acc: 0.9765\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 2s 39us/sample - loss: 0.0652 - acc: 0.9796\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 2s 40us/sample - loss: 0.0568 - acc: 0.9823\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 2s 40us/sample - loss: 0.0506 - acc: 0.9845\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 3s 46us/sample - loss: 0.0427 - acc: 0.9870\n",
      "Performance with validationData :\n",
      "5000/5000 [==============================] - 0s 64us/sample - loss: 0.1119 - acc: 0.9694\n",
      "Performance with testData :\n",
      "10000/10000 [==============================] - 0s 43us/sample - loss: 0.1068 - acc: 0.9676\n"
     ]
    }
   ],
   "source": [
    "x_train = tf.keras.utils.normalize(x_train , axis = 1 )\n",
    "x_test = tf.keras.utils.normalize(x_test , axis = 1 )\n",
    "x_validate = tf.keras.utils.normalize(x_validate , axis = 1 ) \n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(tf.keras.layers.Dense(64 , activation = tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(64 , activation = tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(10 , activation = tf.nn.softmax))\n",
    "\n",
    "sgd = tf.compat.v1.keras.optimizers.SGD(learning_rate = 0.1 )\n",
    "\n",
    "model.compile( optimizer = sgd , \n",
    "             loss = 'sparse_categorical_crossentropy' ,\n",
    "             metrics = ['accuracy'] ) \n",
    "\n",
    "model.fit(x_train , y_train , epochs = 10  )\n",
    "\n",
    "print(\"Performance with validationData :\")\n",
    "val_loss , val_acc = model.evaluate(x_validate,y_validate)\n",
    "print(\"Performance with testData :\")\n",
    "val_loss , val_acc = model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With normalizing data \n",
    "\n",
    "epochs set as 10 \n",
    "\n",
    "number of hidden layer used are 2 and it has 64 nodes .activation used is relu\n",
    "\n",
    "output has 10 layers and activation used in output layer is softmax \n",
    "\n",
    "Performance :\n",
    "\n",
    "Performance with validationData :\n",
    "    \n",
    "acc: 0.9694\n",
    "    \n",
    "Performance with testData :\n",
    "\n",
    "acc: 0.9676"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 2s 41us/sample - loss: 0.3947 - acc: 0.8885\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 2s 39us/sample - loss: 0.2304 - acc: 0.9336\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 2s 38us/sample - loss: 0.1812 - acc: 0.9459\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 2s 38us/sample - loss: 0.1489 - acc: 0.9558\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 2s 39us/sample - loss: 0.1259 - acc: 0.9626\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 2s 38us/sample - loss: 0.1080 - acc: 0.9675\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 4s 64us/sample - loss: 0.0947 - acc: 0.9709\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 4s 69us/sample - loss: 0.0845 - acc: 0.9750\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 4s 69us/sample - loss: 0.0753 - acc: 0.9770\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 4s 69us/sample - loss: 0.0672 - acc: 0.9796\n",
      "Performance with validationData :\n",
      "5000/5000 [==============================] - 0s 64us/sample - loss: 0.0976 - acc: 0.9714\n",
      "Performance with testData :\n",
      "10000/10000 [==============================] - 0s 43us/sample - loss: 0.1079 - acc: 0.9651\n"
     ]
    }
   ],
   "source": [
    "x_train = tf.keras.utils.normalize(x_train , axis = 1 )\n",
    "x_test = tf.keras.utils.normalize(x_test , axis = 1 )\n",
    "x_validate = tf.keras.utils.normalize(x_validate , axis = 1 ) \n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(tf.keras.layers.Dense(64 , activation = tf.nn.tanh))\n",
    "model.add(tf.keras.layers.Dense(64 , activation = tf.nn.tanh))\n",
    "model.add(tf.keras.layers.Dense(10 , activation = tf.nn.softmax))\n",
    "\n",
    "sgd = tf.compat.v1.keras.optimizers.SGD(learning_rate = 0.1 )\n",
    "\n",
    "model.compile( optimizer = sgd , \n",
    "             loss = 'sparse_categorical_crossentropy' ,\n",
    "             metrics = ['accuracy'] ) \n",
    "\n",
    "model.fit(x_train , y_train , epochs = 10  )\n",
    "\n",
    "print(\"Performance with validationData :\")\n",
    "val_loss , val_acc = model.evaluate(x_validate,y_validate)\n",
    "print(\"Performance with testData :\")\n",
    "val_loss , val_acc = model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With normalizing data \n",
    "\n",
    "epochs set as 10 \n",
    "\n",
    "number of hidden layer used are 2 and it has 64 nodes .activation used is tanh\n",
    "\n",
    "output has 10 layers and activation used in output layer is softmax \n",
    "\n",
    "Performance :\n",
    "\n",
    "Performance with validationData :\n",
    "    \n",
    "acc: 0.9714\n",
    "    \n",
    "Performance with testData :\n",
    "\n",
    "acc: 0.9651"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 4s 78us/sample - loss: 0.4195 - acc: 0.8756\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 4s 71us/sample - loss: 0.2077 - acc: 0.9386\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 4s 68us/sample - loss: 0.1556 - acc: 0.9531\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 4s 72us/sample - loss: 0.1237 - acc: 0.9621\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 4s 75us/sample - loss: 0.1040 - acc: 0.9684\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 4s 72us/sample - loss: 0.0878 - acc: 0.9726\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 4s 72us/sample - loss: 0.0767 - acc: 0.9759\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 4s 71us/sample - loss: 0.0681 - acc: 0.9787\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 4s 71us/sample - loss: 0.0608 - acc: 0.9812\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 4s 72us/sample - loss: 0.0541 - acc: 0.9832\n",
      "Performance with validationData :\n",
      "5000/5000 [==============================] - 0s 71us/sample - loss: 0.0902 - acc: 0.9732\n",
      "Performance with testData :\n",
      "10000/10000 [==============================] - 0s 46us/sample - loss: 0.0976 - acc: 0.9695\n"
     ]
    }
   ],
   "source": [
    "x_train = tf.keras.utils.normalize(x_train , axis = 1 )\n",
    "x_test = tf.keras.utils.normalize(x_test , axis = 1 )\n",
    "x_validate = tf.keras.utils.normalize(x_validate , axis = 1 ) \n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(tf.keras.layers.Dense(64 , activation = tf.nn.leaky_relu))\n",
    "model.add(tf.keras.layers.Dense(64 , activation = tf.nn.leaky_relu))\n",
    "model.add(tf.keras.layers.Dense(10 , activation = tf.nn.softmax))\n",
    "\n",
    "sgd = tf.compat.v1.keras.optimizers.SGD(learning_rate = 0.1 )\n",
    "\n",
    "model.compile( optimizer = sgd , \n",
    "             loss = 'sparse_categorical_crossentropy' ,\n",
    "             metrics = ['accuracy'] ) \n",
    "\n",
    "model.fit(x_train , y_train , epochs = 10  )\n",
    "\n",
    "print(\"Performance with validationData :\")\n",
    "val_loss , val_acc = model.evaluate(x_validate,y_validate)\n",
    "print(\"Performance with testData :\")\n",
    "val_loss , val_acc = model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 3s 55us/sample - loss: 0.4022 - acc: 0.8833\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 4s 70us/sample - loss: 0.1982 - acc: 0.9413\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 4s 71us/sample - loss: 0.1480 - acc: 0.9560\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 4s 71us/sample - loss: 0.1200 - acc: 0.9636\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 4s 71us/sample - loss: 0.0997 - acc: 0.9695\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 4s 71us/sample - loss: 0.0849 - acc: 0.9738\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 4s 71us/sample - loss: 0.0752 - acc: 0.9765\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 4s 71us/sample - loss: 0.0657 - acc: 0.9796\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 4s 71us/sample - loss: 0.0583 - acc: 0.9816\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 4s 72us/sample - loss: 0.0521 - acc: 0.9836\n",
      "Performance with validationData :\n",
      "5000/5000 [==============================] - 0s 70us/sample - loss: 0.0861 - acc: 0.9770\n",
      "Performance with testData :\n",
      "10000/10000 [==============================] - 0s 44us/sample - loss: 0.0924 - acc: 0.9720\n"
     ]
    }
   ],
   "source": [
    "With normalizing data \n",
    "\n",
    "epochs set as 10 \n",
    "\n",
    "number of hidden layer used are 2 and it has 64 nodes .activation used is tanh\n",
    "\n",
    "output has 10 layers and activation used in output layer is softmax \n",
    "\n",
    "Performance :\n",
    "\n",
    "Performance with validationData :\n",
    "    \n",
    "acc: 0.9732\n",
    "    \n",
    "Performance with testData :\n",
    "\n",
    "acc: 0.9695"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Observation :   \n",
    "therefore , the good performing model is\n",
    "\n",
    "2 hidden layers ,\n",
    "\n",
    "64 nodes each  ,  \n",
    "\n",
    "should be test with normalized data .\n",
    "\n",
    "hidden layer activation is leakyReLU .\n",
    "\n",
    "output layer activation is softmax .\n",
    "\n",
    "Since , the testing data accurarcy is more for this model compared to other models .\n",
    "\n",
    "Therefore the above model is the best among all other models tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
