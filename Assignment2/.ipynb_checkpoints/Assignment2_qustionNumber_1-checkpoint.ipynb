{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "import nltk as nltk\n",
    "from gensim.models import Word2Vec \n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import pyplot as plt\n",
    "def cleanText(text):\n",
    "    k= [word.lower() for word in word_tokenize(text) if word.isalpha()]\n",
    "    return(k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsGroup = fetch_20newsgroups(subset='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetched 20-newsGroup dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['from',\n",
       " 'mamatha',\n",
       " 'devineni',\n",
       " 'ratnam',\n",
       " 'subject',\n",
       " 'pens',\n",
       " 'fans',\n",
       " 'reactions',\n",
       " 'organization',\n",
       " 'post',\n",
       " 'office',\n",
       " 'carnegie',\n",
       " 'mellon',\n",
       " 'pittsburgh',\n",
       " 'pa',\n",
       " 'lines',\n",
       " 'i',\n",
       " 'am',\n",
       " 'sure',\n",
       " 'some',\n",
       " 'bashers',\n",
       " 'of',\n",
       " 'pens',\n",
       " 'fans',\n",
       " 'are',\n",
       " 'pretty',\n",
       " 'confused',\n",
       " 'about',\n",
       " 'the',\n",
       " 'lack',\n",
       " 'of',\n",
       " 'any',\n",
       " 'kind',\n",
       " 'of',\n",
       " 'posts',\n",
       " 'about',\n",
       " 'the',\n",
       " 'recent',\n",
       " 'pens',\n",
       " 'massacre',\n",
       " 'of',\n",
       " 'the',\n",
       " 'devils',\n",
       " 'actually',\n",
       " 'i',\n",
       " 'am',\n",
       " 'bit',\n",
       " 'puzzled',\n",
       " 'too',\n",
       " 'and',\n",
       " 'a',\n",
       " 'bit',\n",
       " 'relieved',\n",
       " 'however',\n",
       " 'i',\n",
       " 'am',\n",
       " 'going',\n",
       " 'to',\n",
       " 'put',\n",
       " 'an',\n",
       " 'end',\n",
       " 'to',\n",
       " 'relief',\n",
       " 'with',\n",
       " 'a',\n",
       " 'bit',\n",
       " 'of',\n",
       " 'praise',\n",
       " 'for',\n",
       " 'the',\n",
       " 'pens',\n",
       " 'man',\n",
       " 'they',\n",
       " 'are',\n",
       " 'killing',\n",
       " 'those',\n",
       " 'devils',\n",
       " 'worse',\n",
       " 'than',\n",
       " 'i',\n",
       " 'thought',\n",
       " 'jagr',\n",
       " 'just',\n",
       " 'showed',\n",
       " 'you',\n",
       " 'why',\n",
       " 'he',\n",
       " 'is',\n",
       " 'much',\n",
       " 'better',\n",
       " 'than',\n",
       " 'his',\n",
       " 'regular',\n",
       " 'season',\n",
       " 'stats',\n",
       " 'he',\n",
       " 'is',\n",
       " 'also',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'fo',\n",
       " 'fun',\n",
       " 'to',\n",
       " 'watch',\n",
       " 'in',\n",
       " 'the',\n",
       " 'playoffs',\n",
       " 'bowman',\n",
       " 'should',\n",
       " 'let',\n",
       " 'jagr',\n",
       " 'have',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'fun',\n",
       " 'in',\n",
       " 'the',\n",
       " 'next',\n",
       " 'couple',\n",
       " 'of',\n",
       " 'games',\n",
       " 'since',\n",
       " 'the',\n",
       " 'pens',\n",
       " 'are',\n",
       " 'going',\n",
       " 'to',\n",
       " 'beat',\n",
       " 'the',\n",
       " 'pulp',\n",
       " 'out',\n",
       " 'of',\n",
       " 'jersey',\n",
       " 'anyway',\n",
       " 'i',\n",
       " 'was',\n",
       " 'very',\n",
       " 'disappointed',\n",
       " 'not',\n",
       " 'to',\n",
       " 'see',\n",
       " 'the',\n",
       " 'islanders',\n",
       " 'lose',\n",
       " 'the',\n",
       " 'final',\n",
       " 'regular',\n",
       " 'season',\n",
       " 'game',\n",
       " 'pens',\n",
       " 'rule']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goodSentences = []\n",
    "for i in newsGroup.data :\n",
    "    goodSentences.append(cleanText(i))\n",
    "goodSentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spilted each paragraph into list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(goodSentences, min_count = 10, size = 100, window = 5, sg = 1) \n",
    "model3 = gensim.models.Word2Vec(goodSentences,min_count=10,size=100,sg=0,window=5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now each word is represented as Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=21178, size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print(model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21178\n"
     ]
    }
   ],
   "source": [
    "vocabulary = list(model.wv.vocab) \n",
    "print(len(vocabulary))\n",
    "vocabulary = list(model3.wv.vocab) \n",
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocabulary size is 21178"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tires', 0.7761929035186768), ('sentra', 0.7643634080886841), ('civic', 0.7549349069595337), ('corvette', 0.7503450512886047), ('bicycle', 0.743170976638794), ('svx', 0.7428869605064392), ('taurus', 0.7406368255615234), ('honda', 0.7394423484802246), ('saab', 0.7375311255455017), ('rebuilt', 0.7324013710021973), ('toyota', 0.7282315492630005), ('dealership', 0.7260369062423706), ('audi', 0.7259323000907898), ('mpg', 0.7249321937561035), ('nissan', 0.723705530166626), ('camry', 0.7227252721786499), ('mazda', 0.7214208841323853), ('accord', 0.7212908267974854), ('volvo', 0.7180519104003906), ('celica', 0.7120503187179565)]\n"
     ]
    }
   ],
   "source": [
    "similarWords = model.wv.most_similar('car',topn=20)\t\n",
    "print(similarWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above are the top 20 similar words for car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('son', 0.6631417274475098), ('womb', 0.6536429524421692), ('flesh', 0.6494342088699341), ('elohim', 0.6279438734054565), ('enmity', 0.6245716214179993)]\n",
      "[('golf', 0.5690367221832275), ('roster', 0.5235099792480469), ('soccer', 0.5233004689216614), ('sport', 0.5214074850082397), ('film', 0.5184469223022461)]\n"
     ]
    }
   ],
   "source": [
    "result = model.wv.most_similar(positive=['girl', 'father'], negative=['boy'] ,topn=5 )\n",
    "print(result)\n",
    "result = model.wv.most_similar(positive=['sports', 'ball'], negative=['bat'] ,topn=5 )\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above are the top 5 similar words for girl + father - boy\n",
    "Above are the top 5 similar words for sports - bat + ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "pltWord=['baseball','software','police', 'government', 'circuit', 'car']\n",
    "X = np.zeros((120,100))\n",
    "i=0\n",
    "for word in pltWord:\n",
    "  similarWords =  model.wv.most_similar(word,topn=20)\n",
    "  for simWord in similarWords:\n",
    "    X[i]=model[simWord[0]]\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-7313864d9e33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX2_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X2' is not defined"
     ]
    }
   ],
   "source": [
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "X_2d = tsne.fit_transform(X)\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "X2_2d = tsne.fit_transform(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_2d' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9aa7db56958c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mX_2d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mX_2d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_2d' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = ['r', 'g', 'b', 'c', 'm', 'y']\n",
    "labels=['baseball','software','police', 'government', 'circuit', 'car']\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.title(\"SKip gram Model\")\n",
    "for i in range(0,6):\n",
    "  c =colors[i]\n",
    "  x= X_2d[20*i:20*(i+1)-1,0]\n",
    "  y= X_2d[20*i:20*(i+1)-1,1]\n",
    "  plt.scatter(x,y,c=c,label=labels[i])\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.title(\"CBOW Model\")\n",
    "for i in range(0,6):\n",
    "    c =colors[i]\n",
    "    x= X2_2d[20*i:20*(i+1)-1,0]\n",
    "    y= X2_2d[20*i:20*(i+1)-1,1]\n",
    "    ann = similar2[i]\n",
    "    for m in range(0,len(x)):\n",
    "        plt.annotate(similar2[i][m][0],xy=(x[m],y[m]))\n",
    "        plt.scatter(x,y,c=c,label=labels[i])\n",
    "plt.legend()\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorData = np.zeros((len(goodSentences),100))\n",
    "i=0\n",
    "j=0\n",
    "for paragraph in goodSentences:\n",
    "    x = np.zeros((100)) \n",
    "    j = 0 \n",
    "    for word in paragraph :\n",
    "        if word in model.wv :\n",
    "            x = x + model.wv[word] \n",
    "            j = j + 1 \n",
    "    vectorData[i] = x / j \n",
    "    i = i + 1 \n",
    "vectorData = tf.keras.utils.normalize(vectorData)\n",
    "outputData = list(newsGroup.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = tf.keras.Sequential()\n",
    "model1.add(tf.keras.layers.Flatten(input_shape=(100,)))\n",
    "model1.add(tf.keras.layers.Dense(100,activation = tf.nn.tanh))\n",
    "model1.add(tf.keras.layers.Dense(100,activation = tf.nn.leaky_relu))\n",
    "model1.add(tf.keras.layers.Dense(20,activation = tf.nn.softmax ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_testData = vectorData[:int(0.2*len(vectorData))]\n",
    "y_testData = outputData[:int(0.2*len(outputData))]\n",
    "x_trainData = vectorData[int(0.2*len(vectorData)):]\n",
    "y_trainData = outputData[int(0.2*len(outputData)):]\n",
    "\n",
    "\n",
    "y_trainData = np.array(y_trainData)\n",
    "y_testData = np.array(y_testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer='adam',\n",
    "               loss= tf.keras.losses.sparse_categorical_crossentropy\n",
    "               , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13569 samples, validate on 1508 samples\n",
      "Epoch 1/100\n",
      "13569/13569 [==============================] - 1s 39us/sample - loss: 0.4011 - acc: 0.8614 - val_loss: 0.6652 - val_acc: 0.7858\n",
      "Epoch 2/100\n",
      "13569/13569 [==============================] - 0s 36us/sample - loss: 0.3923 - acc: 0.8658 - val_loss: 0.6862 - val_acc: 0.7732\n",
      "Epoch 3/100\n",
      "13569/13569 [==============================] - 1s 38us/sample - loss: 0.3942 - acc: 0.8623 - val_loss: 0.6918 - val_acc: 0.7785\n",
      "Epoch 4/100\n",
      "13569/13569 [==============================] - 0s 36us/sample - loss: 0.3907 - acc: 0.8634 - val_loss: 0.6889 - val_acc: 0.7739\n",
      "Epoch 5/100\n",
      "13569/13569 [==============================] - 0s 35us/sample - loss: 0.3863 - acc: 0.8648 - val_loss: 0.6950 - val_acc: 0.7732\n",
      "Epoch 6/100\n",
      "13569/13569 [==============================] - 0s 34us/sample - loss: 0.3831 - acc: 0.8684 - val_loss: 0.6843 - val_acc: 0.7679\n",
      "Epoch 7/100\n",
      "13569/13569 [==============================] - 0s 35us/sample - loss: 0.3826 - acc: 0.8640 - val_loss: 0.6874 - val_acc: 0.7785\n",
      "Epoch 8/100\n",
      "13569/13569 [==============================] - 0s 35us/sample - loss: 0.3809 - acc: 0.8671 - val_loss: 0.6760 - val_acc: 0.7798\n",
      "Epoch 9/100\n",
      "13569/13569 [==============================] - 0s 34us/sample - loss: 0.3747 - acc: 0.8699 - val_loss: 0.6846 - val_acc: 0.7818\n",
      "Epoch 10/100\n",
      "13569/13569 [==============================] - 0s 34us/sample - loss: 0.3748 - acc: 0.8703 - val_loss: 0.6959 - val_acc: 0.7792\n",
      "Epoch 11/100\n",
      "13569/13569 [==============================] - 1s 42us/sample - loss: 0.3711 - acc: 0.8723 - val_loss: 0.7060 - val_acc: 0.7699\n",
      "Epoch 12/100\n",
      "13569/13569 [==============================] - 0s 36us/sample - loss: 0.3692 - acc: 0.8719 - val_loss: 0.7038 - val_acc: 0.7719\n",
      "Epoch 13/100\n",
      "13569/13569 [==============================] - 0s 36us/sample - loss: 0.3675 - acc: 0.8710 - val_loss: 0.6933 - val_acc: 0.7798\n",
      "Epoch 14/100\n",
      "13569/13569 [==============================] - 0s 35us/sample - loss: 0.3655 - acc: 0.8726 - val_loss: 0.7041 - val_acc: 0.7699\n",
      "Epoch 15/100\n",
      "13569/13569 [==============================] - 1s 42us/sample - loss: 0.3590 - acc: 0.8777 - val_loss: 0.7026 - val_acc: 0.7818\n",
      "Epoch 16/100\n",
      "13569/13569 [==============================] - 0s 36us/sample - loss: 0.3644 - acc: 0.8724 - val_loss: 0.6915 - val_acc: 0.7779\n",
      "Epoch 17/100\n",
      "13569/13569 [==============================] - 0s 36us/sample - loss: 0.3562 - acc: 0.8761 - val_loss: 0.6995 - val_acc: 0.7739\n",
      "Epoch 18/100\n",
      "13569/13569 [==============================] - 0s 31us/sample - loss: 0.3555 - acc: 0.8755 - val_loss: 0.7158 - val_acc: 0.7692\n",
      "Epoch 19/100\n",
      "13569/13569 [==============================] - 0s 32us/sample - loss: 0.3643 - acc: 0.8734 - val_loss: 0.7060 - val_acc: 0.7732\n",
      "Epoch 20/100\n",
      "13569/13569 [==============================] - 1s 38us/sample - loss: 0.3470 - acc: 0.8808 - val_loss: 0.7112 - val_acc: 0.7759\n",
      "Epoch 21/100\n",
      "13569/13569 [==============================] - 1s 73us/sample - loss: 0.3470 - acc: 0.8800 - val_loss: 0.7036 - val_acc: 0.7838\n",
      "Epoch 22/100\n",
      "13569/13569 [==============================] - 1s 74us/sample - loss: 0.3475 - acc: 0.8771 - val_loss: 0.7091 - val_acc: 0.7812\n",
      "Epoch 23/100\n",
      "13569/13569 [==============================] - 1s 65us/sample - loss: 0.3425 - acc: 0.8804 - val_loss: 0.7261 - val_acc: 0.7672\n",
      "Epoch 24/100\n",
      "13569/13569 [==============================] - 1s 64us/sample - loss: 0.3714 - acc: 0.8724 - val_loss: 0.7142 - val_acc: 0.7752\n",
      "Epoch 25/100\n",
      "13569/13569 [==============================] - 0s 31us/sample - loss: 0.3371 - acc: 0.8829 - val_loss: 0.7080 - val_acc: 0.7805\n",
      "Epoch 26/100\n",
      "13569/13569 [==============================] - 0s 32us/sample - loss: 0.3421 - acc: 0.8816 - val_loss: 0.7231 - val_acc: 0.7739\n",
      "Epoch 27/100\n",
      "13569/13569 [==============================] - 0s 31us/sample - loss: 0.3347 - acc: 0.8834 - val_loss: 0.7052 - val_acc: 0.7765\n",
      "Epoch 28/100\n",
      "13569/13569 [==============================] - 0s 29us/sample - loss: 0.3326 - acc: 0.8833 - val_loss: 0.7344 - val_acc: 0.7732\n",
      "Epoch 29/100\n",
      "13569/13569 [==============================] - 0s 30us/sample - loss: 0.3411 - acc: 0.8799 - val_loss: 0.7247 - val_acc: 0.7719\n",
      "Epoch 30/100\n",
      "13569/13569 [==============================] - 0s 31us/sample - loss: 0.3276 - acc: 0.8882 - val_loss: 0.7187 - val_acc: 0.7885\n",
      "Epoch 31/100\n",
      "13569/13569 [==============================] - 0s 32us/sample - loss: 0.3263 - acc: 0.8869 - val_loss: 0.7062 - val_acc: 0.7785\n",
      "Epoch 32/100\n",
      "13569/13569 [==============================] - 1s 44us/sample - loss: 0.3266 - acc: 0.8844 - val_loss: 0.7130 - val_acc: 0.7825\n",
      "Epoch 33/100\n",
      "13569/13569 [==============================] - 1s 65us/sample - loss: 0.3233 - acc: 0.8881 - val_loss: 0.7241 - val_acc: 0.7858\n",
      "Epoch 34/100\n",
      "13569/13569 [==============================] - 1s 64us/sample - loss: 0.3329 - acc: 0.8845 - val_loss: 0.7322 - val_acc: 0.7725\n",
      "Epoch 35/100\n",
      "13569/13569 [==============================] - 1s 77us/sample - loss: 0.3242 - acc: 0.8909 - val_loss: 0.7273 - val_acc: 0.7759\n",
      "Epoch 36/100\n",
      "13569/13569 [==============================] - 1s 76us/sample - loss: 0.3143 - acc: 0.8902 - val_loss: 0.7373 - val_acc: 0.7752\n",
      "Epoch 37/100\n",
      "13569/13569 [==============================] - 1s 75us/sample - loss: 0.3151 - acc: 0.8908 - val_loss: 0.7403 - val_acc: 0.7692\n",
      "Epoch 38/100\n",
      "13569/13569 [==============================] - 1s 77us/sample - loss: 0.3173 - acc: 0.8888 - val_loss: 0.7487 - val_acc: 0.7779\n",
      "Epoch 39/100\n",
      "13569/13569 [==============================] - 1s 79us/sample - loss: 0.3224 - acc: 0.8897 - val_loss: 0.7225 - val_acc: 0.7765\n",
      "Epoch 40/100\n",
      "13569/13569 [==============================] - 1s 74us/sample - loss: 0.3046 - acc: 0.8962 - val_loss: 0.7429 - val_acc: 0.7845\n",
      "Epoch 41/100\n",
      "13569/13569 [==============================] - 1s 71us/sample - loss: 0.3050 - acc: 0.8973 - val_loss: 0.7452 - val_acc: 0.7785\n",
      "Epoch 42/100\n",
      "13569/13569 [==============================] - 1s 77us/sample - loss: 0.3051 - acc: 0.8975 - val_loss: 0.7578 - val_acc: 0.7845\n",
      "Epoch 43/100\n",
      "13569/13569 [==============================] - 1s 64us/sample - loss: 0.3139 - acc: 0.8914 - val_loss: 0.7645 - val_acc: 0.7845\n",
      "Epoch 44/100\n",
      "13569/13569 [==============================] - 1s 64us/sample - loss: 0.3102 - acc: 0.8934 - val_loss: 0.7457 - val_acc: 0.7772\n",
      "Epoch 45/100\n",
      "13569/13569 [==============================] - 1s 65us/sample - loss: 0.2977 - acc: 0.8966 - val_loss: 0.7578 - val_acc: 0.7825\n",
      "Epoch 46/100\n",
      "13569/13569 [==============================] - 1s 66us/sample - loss: 0.2934 - acc: 0.8985 - val_loss: 0.7668 - val_acc: 0.7752\n",
      "Epoch 47/100\n",
      "13569/13569 [==============================] - 1s 67us/sample - loss: 0.2978 - acc: 0.8976 - val_loss: 0.7630 - val_acc: 0.7699\n",
      "Epoch 48/100\n",
      "13569/13569 [==============================] - 1s 65us/sample - loss: 0.2922 - acc: 0.9004 - val_loss: 0.7603 - val_acc: 0.7725\n",
      "Epoch 49/100\n",
      "13569/13569 [==============================] - 1s 64us/sample - loss: 0.2882 - acc: 0.9020 - val_loss: 0.7610 - val_acc: 0.7838\n",
      "Epoch 50/100\n",
      "13569/13569 [==============================] - 1s 81us/sample - loss: 0.2864 - acc: 0.9040 - val_loss: 0.7747 - val_acc: 0.7759\n",
      "Epoch 51/100\n",
      "13569/13569 [==============================] - 1s 84us/sample - loss: 0.2880 - acc: 0.9026 - val_loss: 0.7534 - val_acc: 0.7765\n",
      "Epoch 52/100\n",
      "13569/13569 [==============================] - 1s 68us/sample - loss: 0.2919 - acc: 0.8976 - val_loss: 0.7826 - val_acc: 0.7712\n",
      "Epoch 53/100\n",
      "13569/13569 [==============================] - 1s 86us/sample - loss: 0.2907 - acc: 0.9021 - val_loss: 0.7703 - val_acc: 0.7752\n",
      "Epoch 54/100\n",
      "13569/13569 [==============================] - 1s 77us/sample - loss: 0.2777 - acc: 0.9049 - val_loss: 0.7863 - val_acc: 0.7672\n",
      "Epoch 55/100\n",
      "13569/13569 [==============================] - 1s 69us/sample - loss: 0.2799 - acc: 0.9032 - val_loss: 0.7755 - val_acc: 0.7805\n",
      "Epoch 56/100\n",
      "13569/13569 [==============================] - 1s 85us/sample - loss: 0.2792 - acc: 0.9044 - val_loss: 0.7979 - val_acc: 0.7699\n",
      "Epoch 57/100\n",
      "13569/13569 [==============================] - 1s 77us/sample - loss: 0.2765 - acc: 0.9069 - val_loss: 0.7602 - val_acc: 0.7832\n",
      "Epoch 58/100\n",
      "13569/13569 [==============================] - 1s 74us/sample - loss: 0.2738 - acc: 0.9060 - val_loss: 0.7726 - val_acc: 0.7865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "13569/13569 [==============================] - 1s 83us/sample - loss: 0.2837 - acc: 0.9039 - val_loss: 0.8051 - val_acc: 0.7759\n",
      "Epoch 60/100\n",
      "13569/13569 [==============================] - 1s 80us/sample - loss: 0.2701 - acc: 0.9077 - val_loss: 0.7864 - val_acc: 0.7765\n",
      "Epoch 61/100\n",
      "13569/13569 [==============================] - 1s 70us/sample - loss: 0.2868 - acc: 0.9015 - val_loss: 0.8010 - val_acc: 0.7759\n",
      "Epoch 62/100\n",
      "13569/13569 [==============================] - 1s 69us/sample - loss: 0.2646 - acc: 0.9103 - val_loss: 0.7942 - val_acc: 0.7739\n",
      "Epoch 63/100\n",
      "13569/13569 [==============================] - 1s 65us/sample - loss: 0.2642 - acc: 0.9108 - val_loss: 0.7840 - val_acc: 0.7825\n",
      "Epoch 64/100\n",
      "13569/13569 [==============================] - 1s 66us/sample - loss: 0.2645 - acc: 0.9088 - val_loss: 0.8346 - val_acc: 0.7779\n",
      "Epoch 65/100\n",
      "13569/13569 [==============================] - 1s 63us/sample - loss: 0.2739 - acc: 0.9049 - val_loss: 0.8223 - val_acc: 0.7752\n",
      "Epoch 66/100\n",
      "13569/13569 [==============================] - 1s 62us/sample - loss: 0.2598 - acc: 0.9130 - val_loss: 0.8189 - val_acc: 0.7785\n",
      "Epoch 67/100\n",
      "13569/13569 [==============================] - 1s 63us/sample - loss: 0.2574 - acc: 0.9094 - val_loss: 0.8230 - val_acc: 0.7626\n",
      "Epoch 68/100\n",
      "13569/13569 [==============================] - 1s 64us/sample - loss: 0.2634 - acc: 0.9088 - val_loss: 0.8200 - val_acc: 0.7765\n",
      "Epoch 69/100\n",
      "13569/13569 [==============================] - 1s 70us/sample - loss: 0.2524 - acc: 0.9158 - val_loss: 0.8255 - val_acc: 0.7745\n",
      "Epoch 70/100\n",
      "13569/13569 [==============================] - 1s 78us/sample - loss: 0.2544 - acc: 0.9138 - val_loss: 0.8089 - val_acc: 0.7706\n",
      "Epoch 71/100\n",
      "13569/13569 [==============================] - 1s 78us/sample - loss: 0.2538 - acc: 0.9126 - val_loss: 0.8112 - val_acc: 0.7798\n",
      "Epoch 72/100\n",
      "13569/13569 [==============================] - 1s 73us/sample - loss: 0.2522 - acc: 0.9130 - val_loss: 0.8292 - val_acc: 0.7719\n",
      "Epoch 73/100\n",
      "13569/13569 [==============================] - 1s 71us/sample - loss: 0.2495 - acc: 0.9138 - val_loss: 0.8236 - val_acc: 0.7792\n",
      "Epoch 74/100\n",
      "13569/13569 [==============================] - 1s 66us/sample - loss: 0.2473 - acc: 0.9162 - val_loss: 0.8089 - val_acc: 0.7725\n",
      "Epoch 75/100\n",
      "13569/13569 [==============================] - 1s 70us/sample - loss: 0.2421 - acc: 0.9193 - val_loss: 0.8242 - val_acc: 0.7759\n",
      "Epoch 76/100\n",
      "13569/13569 [==============================] - 1s 63us/sample - loss: 0.2417 - acc: 0.9195 - val_loss: 0.8459 - val_acc: 0.7812\n",
      "Epoch 77/100\n",
      "13569/13569 [==============================] - 1s 62us/sample - loss: 0.2428 - acc: 0.9159 - val_loss: 0.8292 - val_acc: 0.7838\n",
      "Epoch 78/100\n",
      "13569/13569 [==============================] - 1s 70us/sample - loss: 0.2419 - acc: 0.9169 - val_loss: 0.8309 - val_acc: 0.7825\n",
      "Epoch 79/100\n",
      "13569/13569 [==============================] - 1s 66us/sample - loss: 0.2433 - acc: 0.9186 - val_loss: 0.8583 - val_acc: 0.7772\n",
      "Epoch 80/100\n",
      "13569/13569 [==============================] - 1s 63us/sample - loss: 0.2370 - acc: 0.9215 - val_loss: 0.8705 - val_acc: 0.7712\n",
      "Epoch 81/100\n",
      "13569/13569 [==============================] - 1s 63us/sample - loss: 0.2354 - acc: 0.9201 - val_loss: 0.8654 - val_acc: 0.7765\n",
      "Epoch 82/100\n",
      "13569/13569 [==============================] - 1s 62us/sample - loss: 0.2326 - acc: 0.9208 - val_loss: 0.8623 - val_acc: 0.7739\n",
      "Epoch 83/100\n",
      "13569/13569 [==============================] - 1s 63us/sample - loss: 0.2342 - acc: 0.9228 - val_loss: 0.8470 - val_acc: 0.7772\n",
      "Epoch 84/100\n",
      "13569/13569 [==============================] - 1s 62us/sample - loss: 0.2291 - acc: 0.9248 - val_loss: 0.8672 - val_acc: 0.7706\n",
      "Epoch 85/100\n",
      "13569/13569 [==============================] - 1s 67us/sample - loss: 0.2329 - acc: 0.9216 - val_loss: 0.8667 - val_acc: 0.7739\n",
      "Epoch 86/100\n",
      "13569/13569 [==============================] - 1s 70us/sample - loss: 0.2283 - acc: 0.9217 - val_loss: 0.8516 - val_acc: 0.7785\n",
      "Epoch 87/100\n",
      "13569/13569 [==============================] - 1s 69us/sample - loss: 0.2274 - acc: 0.9222 - val_loss: 0.8604 - val_acc: 0.7838\n",
      "Epoch 88/100\n",
      "13569/13569 [==============================] - 1s 66us/sample - loss: 0.2244 - acc: 0.9273 - val_loss: 0.8784 - val_acc: 0.7845\n",
      "Epoch 89/100\n",
      "13569/13569 [==============================] - 1s 63us/sample - loss: 0.2387 - acc: 0.9183 - val_loss: 0.8686 - val_acc: 0.7719\n",
      "Epoch 90/100\n",
      "13569/13569 [==============================] - 1s 66us/sample - loss: 0.2167 - acc: 0.9277 - val_loss: 0.8906 - val_acc: 0.7686\n",
      "Epoch 91/100\n",
      "13569/13569 [==============================] - 1s 63us/sample - loss: 0.2220 - acc: 0.9238 - val_loss: 0.9133 - val_acc: 0.7639\n",
      "Epoch 92/100\n",
      "13569/13569 [==============================] - 1s 62us/sample - loss: 0.2204 - acc: 0.9258 - val_loss: 0.8633 - val_acc: 0.7858\n",
      "Epoch 93/100\n",
      "13569/13569 [==============================] - 1s 62us/sample - loss: 0.2159 - acc: 0.9279 - val_loss: 0.8625 - val_acc: 0.7745\n",
      "Epoch 94/100\n",
      "13569/13569 [==============================] - 1s 65us/sample - loss: 0.2163 - acc: 0.9279 - val_loss: 0.8830 - val_acc: 0.7845\n",
      "Epoch 95/100\n",
      "13569/13569 [==============================] - 1s 64us/sample - loss: 0.2356 - acc: 0.9212 - val_loss: 0.9098 - val_acc: 0.7613\n",
      "Epoch 96/100\n",
      "13569/13569 [==============================] - 1s 63us/sample - loss: 0.2106 - acc: 0.9315 - val_loss: 0.9029 - val_acc: 0.7772\n",
      "Epoch 97/100\n",
      "13569/13569 [==============================] - 1s 68us/sample - loss: 0.2204 - acc: 0.9231 - val_loss: 0.9128 - val_acc: 0.7646\n",
      "Epoch 98/100\n",
      "13569/13569 [==============================] - 1s 66us/sample - loss: 0.2061 - acc: 0.9298 - val_loss: 0.8894 - val_acc: 0.7759\n",
      "Epoch 99/100\n",
      "13569/13569 [==============================] - 1s 67us/sample - loss: 0.2135 - acc: 0.9280 - val_loss: 0.9186 - val_acc: 0.7745\n",
      "Epoch 100/100\n",
      "13569/13569 [==============================] - 1s 72us/sample - loss: 0.2030 - acc: 0.9320 - val_loss: 0.8802 - val_acc: 0.7772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff29c425b38>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(x_trainData,y_trainData,epochs=100,shuffle=True,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance with testData :\n",
      "3769/3769 [==============================] - 0s 22us/sample - loss: 0.8017 - acc: 0.7588\n"
     ]
    }
   ],
   "source": [
    "print(\"Performance with testData :\")\n",
    "val_loss , val_acc = model1.evaluate(x_testData,y_testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
