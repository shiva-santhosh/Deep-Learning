{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models,preprocessing\n",
    "from nltk.corpus import stopwords \n",
    "from nltk import RegexpTokenizer\n",
    "import nltk\n",
    "import re\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = open('train.txt').readlines()\n",
    "test_data = open('test.txt').readlines()\n",
    "general_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neat_paragraphs(paragraph_list) :\n",
    "    neat_sentences = []\n",
    "    clean = re.compile('<.*?>')\n",
    "    for i in range(len(paragraph_list)) :\n",
    "        paragraph_list[i] = re.sub(clean,'',paragraph_list[i])\n",
    "    reg_tokens = RegexpTokenizer(r'\\w+')\n",
    "    for i in paragraph_list :\n",
    "        tokens = reg_tokens.tokenize(i.lower())\n",
    "        neat_sentences.append([word for word in tokens if word not in general_words and word.isalpha()])\n",
    "    neat_paragraphs=[]\n",
    "    for i in neat_sentences :\n",
    "        neat_paragraphs.append(\" \".join(i))\n",
    "    return neat_paragraphs\n",
    "def vector_encoding(train_data,test_data):\n",
    "    tokenizer = preprocessing.text.Tokenizer()\n",
    "    tokenizer.fit_on_texts(train_data+test_data)\n",
    "    train_encoded = tokenizer.texts_to_sequences(train_data)\n",
    "    test_encoded = tokenizer.texts_to_sequences(test_data)\n",
    "    padded_train = preprocessing.sequence.pad_sequences(train_encoded,\n",
    "                                                              padding='post',maxlen=200)\n",
    "    padded_test = preprocessing.sequence.pad_sequences(test_encoded,\n",
    "                                                              padding='post',maxlen=200)\n",
    "    vocab_size = len(tokenizer.word_index)+1\n",
    "    return (vocab_size,padded_train,padded_test)\n",
    "\n",
    "train_data = neat_paragraphs(train_data)\n",
    "test_data = neat_paragraphs(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = [1]*12500\n",
    "test_label = [1]*12500\n",
    "dummy = [0]*12500\n",
    "train_label = train_label + dummy \n",
    "test_label = test_label + dummy\n",
    "size,train_vector,test_vector = vector_encoding(train_data,test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 128)         12998272  \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 200)               65800     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 13,064,273\n",
      "Trainable params: 13,064,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = models.Sequential()\n",
    "model1.add(layers.Embedding(size,128))\n",
    "model1.add(layers.SimpleRNN(units=200,activation='tanh'))\n",
    "model1.add(layers.Dense(1,activation='sigmoid'))\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "20000/20000 [==============================] - 161s 8ms/sample - loss: 0.6662 - acc: 0.6197 - val_loss: 0.9982 - val_acc: 0.0012\n",
      "Epoch 2/5\n",
      "20000/20000 [==============================] - 158s 8ms/sample - loss: 0.6562 - acc: 0.6304 - val_loss: 1.0527 - val_acc: 0.0342\n",
      "Epoch 3/5\n",
      "20000/20000 [==============================] - 161s 8ms/sample - loss: 0.6321 - acc: 0.6417 - val_loss: 1.0945 - val_acc: 0.0634\n",
      "Epoch 4/5\n",
      "20000/20000 [==============================] - 159s 8ms/sample - loss: 0.6199 - acc: 0.6432 - val_loss: 1.0414 - val_acc: 0.1092\n",
      "Epoch 5/5\n",
      "20000/20000 [==============================] - 160s 8ms/sample - loss: 0.6189 - acc: 0.6461 - val_loss: 1.0702 - val_acc: 0.1166\n"
     ]
    }
   ],
   "source": [
    "model1.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "history = model1.fit(train_vector,train_label,epochs=5,shuffle=True,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model1  output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 - 25s - loss: 0.7674 - acc: 0.5054\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'], label='accuracy')\n",
    "plt.plot(history.history['val_acc'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "test_loss, test_acc = model1.evaluate(test_vector,  test_label, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 128)         12998272  \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm (CuDNNLSTM)       (None, 200)               264000    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 13,262,473\n",
      "Trainable params: 13,262,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = models.Sequential()\n",
    "model2.add(layers.Embedding(size,128))\n",
    "model2.add(layers.CuDNNLSTM(units=200))\n",
    "model2.add(layers.Dense(1,activation='sigmoid'))\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run in with google colab for outputs of remaining models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "No OpKernel was registered to support Op 'CudnnRNN' used by node cu_dnnlstm/CudnnRNN (defined at <ipython-input-24-e0dc5012fb93>:3) with these attrs: [T=DT_FLOAT, input_mode=\"linear_input\", direction=\"unidirectional\", rnn_mode=\"lstm\", is_training=true, seed2=0, seed=0, dropout=0]\nRegistered devices: [CPU, XLA_CPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[cu_dnnlstm/CudnnRNN]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1339\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: No OpKernel was registered to support Op 'CudnnRNN' used by {{node cu_dnnlstm/CudnnRNN}}with these attrs: [T=DT_FLOAT, input_mode=\"linear_input\", direction=\"unidirectional\", rnn_mode=\"lstm\", is_training=true, seed2=0, seed=0, dropout=0]\nRegistered devices: [CPU, XLA_CPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[cu_dnnlstm/CudnnRNN]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-ad2d9889a1eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_vector\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;31m# Setup work for each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mreset_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'metrics'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m         \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m     \u001b[0;31m# Reset the state of loss metric wrappers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/metrics.py\u001b[0m in \u001b[0;36mreset_states\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mwhen\u001b[0m \u001b[0ma\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mevaluated\u001b[0m \u001b[0mduring\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \"\"\"\n\u001b[0;32m--> 199\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   3069\u001b[0m           \u001b[0massign_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3070\u001b[0m           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3071\u001b[0;31m         \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m(op_input_list)\u001b[0m\n\u001b[1;32m    460\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    877\u001b[0m     \u001b[0;31m# marked as initialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m     is_initialized = session.run(\n\u001b[0;32m--> 879\u001b[0;31m         [variables_module.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[1;32m    880\u001b[0m     \u001b[0muninitialized_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1368\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: No OpKernel was registered to support Op 'CudnnRNN' used by node cu_dnnlstm/CudnnRNN (defined at <ipython-input-24-e0dc5012fb93>:3) with these attrs: [T=DT_FLOAT, input_mode=\"linear_input\", direction=\"unidirectional\", rnn_mode=\"lstm\", is_training=true, seed2=0, seed=0, dropout=0]\nRegistered devices: [CPU, XLA_CPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[cu_dnnlstm/CudnnRNN]]"
     ]
    }
   ],
   "source": [
    "model2.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "history = model2.fit(train_vector,train_label,epochs=5,shuffle=True,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model2 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'], label='accuracy')\n",
    "plt.plot(history.history['val_acc'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model2.evaluate(test_vector,  test_label, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 128)         12998272  \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 200)               197400    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 13,195,873\n",
      "Trainable params: 13,195,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = models.Sequential()\n",
    "model3.add(layers.Embedding(size,128))\n",
    "model3.add(layers.GRU(units=200,activation='relu'))\n",
    "model3.add(layers.Dense(1,activation='sigmoid'))\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "history = model3.fit(train_vector,train_label,epochs=5,shuffle=True,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model3 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'], label='accuracy')\n",
    "plt.plot(history.history['val_acc'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model3.evaluate(test_vector,  test_label, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 128)         12998272  \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_3 (CuDNNLSTM)     (None, None, 200)         264000    \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_4 (CuDNNLSTM)     (None, 200)               321600    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 13,584,073\n",
      "Trainable params: 13,584,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4 = models.Sequential()\n",
    "model4.add(layers.Embedding(size,128))\n",
    "model4.add(layers.CuDNNLSTM(units=200,return_sequences=True))\n",
    "model4.add(layers.CuDNNLSTM(units=200))\n",
    "model4.add(layers.Dense(1,activation='sigmoid'))\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "history = model4.fit(train_vector,train_label,epochs=5,shuffle=True,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model4 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'], label='accuracy')\n",
    "plt.plot(history.history['val_acc'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model4.evaluate(test_vector,  test_label, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, None, 128)         12998272  \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_9 (CuDNNLSTM)     (None, None, 200)         264000    \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_10 (CuDNNLSTM)    (None, None, 200)         321600    \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_11 (CuDNNLSTM)    (None, 200)               321600    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 13,905,673\n",
      "Trainable params: 13,905,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model5 = models.Sequential()\n",
    "model5.add(layers.Embedding(size,128))\n",
    "model5.add(layers.CuDNNLSTM(units=200,return_sequences=True))\n",
    "model5.add(layers.CuDNNLSTM(units=200,return_sequences=True))\n",
    "model5.add(layers.CuDNNLSTM(units=200))\n",
    "model5.add(layers.Dense(1,activation='sigmoid'))\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "history = model5.fit(train_vector,train_label,epochs=5,shuffle=True,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model5 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'], label='accuracy')\n",
    "plt.plot(history.history['val_acc'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model5.evaluate(test_vector,  test_label, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
